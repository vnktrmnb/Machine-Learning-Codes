{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rar6LQxZ-QHp",
        "outputId": "1d649968-6990-4fd1-ec65-908b9d5a20cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'precision': array([1., 1., 1.]),\n",
              " 'recall': array([1., 1., 1.]),\n",
              " 'f1_score': array([1., 1., 1.]),\n",
              " 'support': array([19., 13., 13.]),\n",
              " 'accuracy': 1.0,\n",
              " 'macro_avg_precision': 1.0,\n",
              " 'macro_avg_recall': 1.0,\n",
              " 'macro_avg_f1_score': 1.0,\n",
              " 'weighted_avg_precision': 1.0,\n",
              " 'weighted_avg_recall': 1.0,\n",
              " 'weighted_avg_f1_score': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics_from_confusion_matrix(conf_matrix):\n",
        "    # Initialize metrics\n",
        "    precision = np.zeros(3)\n",
        "    recall = np.zeros(3)\n",
        "    f1_score = np.zeros(3)\n",
        "    support = np.zeros(3)\n",
        "\n",
        "    for i in range(3):\n",
        "        tp = conf_matrix[i, i]\n",
        "        fp = conf_matrix[:, i].sum() - tp\n",
        "        fn = conf_matrix[i, :].sum() - tp\n",
        "        tn = conf_matrix.sum() - (tp + fp + fn)\n",
        "\n",
        "        precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1_score[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
        "        support[i] = conf_matrix[i, :].sum()\n",
        "\n",
        "    # Compute averages\n",
        "    accuracy = conf_matrix.diagonal().sum() / conf_matrix.sum()\n",
        "    macro_avg_precision = precision.mean()\n",
        "    macro_avg_recall = recall.mean()\n",
        "    macro_avg_f1_score = f1_score.mean()\n",
        "    weighted_avg_precision = (precision * support).sum() / support.sum()\n",
        "    weighted_avg_recall = (recall * support).sum() / support.sum()\n",
        "    weighted_avg_f1_score = (f1_score * support).sum() / support.sum()\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1_score,\n",
        "        'support': support,\n",
        "        'accuracy': accuracy,\n",
        "        'macro_avg_precision': macro_avg_precision,\n",
        "        'macro_avg_recall': macro_avg_recall,\n",
        "        'macro_avg_f1_score': macro_avg_f1_score,\n",
        "        'weighted_avg_precision': weighted_avg_precision,\n",
        "        'weighted_avg_recall': weighted_avg_recall,\n",
        "        'weighted_avg_f1_score': weighted_avg_f1_score\n",
        "    }\n",
        "\n",
        "# Example confusion matrix for 3 classes\n",
        "conf_matrix = np.array([[19, 0, 0],\n",
        "                        [0, 13, 0],\n",
        "                        [0, 0, 13]])\n",
        "\n",
        "# Compute metrics\n",
        "metrics = compute_metrics_from_confusion_matrix(conf_matrix)\n",
        "\n",
        "metrics\n"
      ]
    }
  ]
}